par(mfrow=c(1,2))
x1 <- seq(0,10,length.out = 6)
prior1 <- dbeta(x1,1,1)
posterior1 <- dbeta(x1,4,9)
x2 <- seq(0,50,length.out = 1)
prior2 <- dbeta(x2,25,1)
posterior2 <- dbeta(x2,28,9)
plot(prior1, type = "l", lwd = 2, col = "red", ylim = c(0,4), xlab = "x",
ylab = "beta distribution")
lines(posterior1, type="l", lwd=2, col="blue")
legend("topright",
legend=c("prior1", "posterior1"),
col=c("red", "blue"),
lwd=2)
plot(prior2, type = "l", lwd = 2, col="red", ylim = c(0,4), xlab = "x",
ylab = "beta distribution")
lines(posterior2, type="l", lwd=2, col="blue")
legend("topright",
legend=c("prior2", "posterior2"),
col=c("red", "blue"),
lwd=2)
par(mfrow=c(1,2))
x1 <- seq(0,10,length.out = 10)
prior1 <- dbeta(x1,1,1)
posterior1 <- dbeta(x1,4,9)
x2 <- seq(0,50,length.out = 5)
prior2 <- dbeta(x2,25,1)
posterior2 <- dbeta(x2,28,9)
plot(prior1, type = "l", lwd = 2, col = "red", ylim = c(0,4), xlab = "x",
ylab = "beta distribution")
lines(posterior1, type="l", lwd=2, col="blue")
legend("topright",
legend=c("prior1", "posterior1"),
col=c("red", "blue"),
lwd=2)
plot(prior2, type = "l", lwd = 2, col="red", ylim = c(0,4), xlab = "x",
ylab = "beta distribution")
lines(posterior2, type="l", lwd=2, col="blue")
legend("topright",
legend=c("prior2", "posterior2"),
col=c("red", "blue"),
lwd=2)
par(mfrow=c(1,2))
x1 <- seq(0,10,length.out = 10)
prior1 <- dbeta(x1,1,1)
posterior1 <- dbeta(x1,4,9)
x2 <- seq(0,50,length.out = 5)
prior2 <- dbeta(x2,25,1)
posterior2 <- dbeta(x2,28,9)
plot(x1, prior1, type = "l", lwd = 2, col = "red", ylim = c(0,4), xlab = "x",
ylab = "beta distribution")
lines(x1, posterior1, type="l", lwd=2, col="blue")
legend("topright",
legend=c("prior1", "posterior1"),
col=c("red", "blue"),
lwd=2)
plot(x2, prior2, type = "l", lwd = 2, col="red", ylim = c(0,4), xlab = "x",
ylab = "beta distribution")
lines(x2, posterior2, type="l", lwd=2, col="blue")
legend("topright",
legend=c("prior2", "posterior2"),
col=c("red", "blue"),
lwd=2)
par(mfrow=c(1,2))
x1 <- seq(0,20,length.out = 100)
prior1 <- dbeta(x1,1,1)
posterior1 <- dbeta(x1,4,9)
x2 <- seq(0,10,length.out = 100)
prior2 <- dbeta(x2,25,1)
posterior2 <- dbeta(x2,28,9)
plot(x1, prior1, type = "l", lwd = 2, col = "red", ylim = c(0,4), xlab = "x",
ylab = "beta distribution")
lines(x1, posterior1, type="l", lwd=2, col="blue")
legend("topright",
legend=c("prior1", "posterior1"),
col=c("red", "blue"),
lwd=2)
plot(x2, prior2, type = "l", lwd = 2, col="red", ylim = c(0,4), xlab = "x",
ylab = "beta distribution")
lines(x2, posterior2, type="l", lwd=2, col="blue")
legend("topright",
legend=c("prior2", "posterior2"),
col=c("red", "blue"),
lwd=2)
par(mfrow=c(1,2))
x1 <- seq(0,20,length.out = 100)
prior1 <- dbeta(x1,1,1)
posterior1 <- dbeta(x1,4,9)
x2 <- seq(0,10,length.out = 100)
prior2 <- dbeta(x2,25,1)
posterior2 <- dbeta(x2,28,9)
plot(x1, prior1, type = "l", lwd = 2, col = "red", ylim = c(0,4), xlab = "x",
ylab = "beta distribution")
lines(x1, posterior1, type="l", lwd=2, col="blue")
legend("topright",
legend=c("prior1", "posterior1"),
col=c("red", "blue"),
lwd=2)
plot(x2, prior2, type = "l", lwd = 2, col="red", ylim = c(0,8), xlab = "x",
ylab = "beta distribution")
lines(x2, posterior2, type="l", lwd=2, col="blue")
legend("topright",
legend=c("prior2", "posterior2"),
col=c("red", "blue"),
lwd=2)
par(mfrow=c(1,2))
x1 <- seq(0,2,length.out = 100)
prior1 <- dbeta(x1,1,1)
posterior1 <- dbeta(x1,4,9)
x2 <- seq(0,2,length.out = 100)
prior2 <- dbeta(x2,25,1)
posterior2 <- dbeta(x2,28,9)
plot(x1, prior1, type = "l", lwd = 2, col = "red", ylim = c(0,4), xlab = "x",
ylab = "beta distribution")
lines(x1, posterior1, type="l", lwd=2, col="blue")
legend("topright",
legend=c("prior1", "posterior1"),
col=c("red", "blue"),
lwd=2)
plot(x2, prior2, type = "l", lwd = 2, col="red", ylim = c(0,6), xlab = "x",
ylab = "beta distribution")
lines(x2, posterior2, type="l", lwd=2, col="blue")
legend("topright",
legend=c("prior2", "posterior2"),
col=c("red", "blue"),
lwd=2)
par(mfrow=c(1,2))
x1 <- seq(0,2,length.out = 100)
prior1 <- dbeta(x1,1,1)
posterior1 <- dbeta(x1,4,9)
x2 <- seq(0.25,1.5,length.out = 100)
prior2 <- dbeta(x2,25,1)
posterior2 <- dbeta(x2,28,9)
plot(x1, prior1, type = "l", lwd = 2, col = "red", ylim = c(0,4), xlab = "x",
ylab = "beta distribution")
lines(x1, posterior1, type="l", lwd=2, col="blue")
legend("topright",
legend=c("prior1", "posterior1"),
col=c("red", "blue"),
lwd=2)
plot(x2, prior2, type = "l", lwd = 2, col="red", ylim = c(0,6), xlab = "x",
ylab = "beta distribution")
lines(x2, posterior2, type="l", lwd=2, col="blue")
legend("topright",
legend=c("prior2", "posterior2"),
col=c("red", "blue"),
lwd=2)
par(mfrow=c(1,2))
x1 <- seq(0,2,length.out = 100)
prior1 <- dbeta(x1,1,1)
posterior1 <- dbeta(x1,4,9)
x2 <- seq(0.25,1.5,length.out = 100)
prior2 <- dbeta(x2,25,1)
posterior2 <- dbeta(x2,28,9)
plot(x1, prior1, type = "l", lwd = 2, col = "red", ylim = c(0,4), xlab = "x",
ylab = "beta distribution")
lines(x1, posterior1, type="l", lwd=2, col="blue")
legend("topright",
legend=c("prior1", "posterior1"),
col=c("red", "blue"),
lwd=2)
plot(x2, prior2, type = "l", lwd = 2, col="red", ylim = c(0,8), xlab = "x",
ylab = "beta distribution")
lines(x2, posterior2, type="l", lwd=2, col="blue")
legend("topright",
legend=c("prior2", "posterior2"),
col=c("red", "blue"),
lwd=2)
par(mfrow=c(1,2))
x1 <- seq(0,2,length.out = 100)
prior1 <- dbeta(x1,1,1)
posterior1 <- dbeta(x1,4,9)
x2 <- seq(0.25,1.5,length.out = 100)
prior2 <- dbeta(x2,25,1)
posterior2 <- dbeta(x2,28,9)
plot(x1, prior1, type = "l", lwd = 2, col = "red", ylim = c(0,4), xlab = "x",
ylab = "beta distribution")
lines(x1, posterior1, type="l", lwd=2, col="blue")
legend("topright",
legend=c("prior1", "posterior1"),
col=c("red", "blue"),
lwd=2)
plot(x2, prior2, type = "l", lwd = 2, col="red", ylim = c(0,10), xlab = "x",
ylab = "beta distribution")
lines(x2, posterior2, type="l", lwd=2, col="blue")
legend("topright",
legend=c("prior2", "posterior2"),
col=c("red", "blue"),
lwd=2)
par(mfrow=c(1,2))
x1 <- seq(0,2,length.out = 100)
prior1 <- dbeta(x1,1,1)
posterior1 <- dbeta(x1,4,9)
x2 <- seq(0.25,1.5,length.out = 100)
prior2 <- dbeta(x2,25,1)
posterior2 <- dbeta(x2,28,9)
plot(x1, prior1, type = "l", lwd = 2, col = "red", ylim = c(0,4), xlab = "x",
ylab = "beta distribution")
lines(x1, posterior1, type="l", lwd=2, col="blue")
legend("topright",
legend=c("prior1", "posterior1"),
col=c("red", "blue"),
lwd=2)
plot(x2, prior2, type = "l", lwd = 2, col="red", ylim = c(0,20), xlab = "x",
ylab = "beta distribution")
lines(x2, posterior2, type="l", lwd=2, col="blue")
legend("topright",
legend=c("prior2", "posterior2"),
col=c("red", "blue"),
lwd=2)
par(mfrow=c(1,2))
x1 <- seq(0,2,length.out = 100)
prior1 <- dbeta(x1,1,1)
posterior1 <- dbeta(x1,4,9)
x2 <- seq(0.25,1.5,length.out = 100)
prior2 <- dbeta(x2,25,1)
posterior2 <- dbeta(x2,28,9)
plot(x1, prior1, type = "l", lwd = 2, col = "red", ylim = c(0,4), xlab = "x",
ylab = "beta distribution")
lines(x1, posterior1, type="l", lwd=2, col="blue")
legend("topright",
legend=c("prior1", "posterior1"),
col=c("red", "blue"),
lwd=2)
plot(x2, prior2, type = "l", lwd = 2, col="red", ylim = c(0,30), xlab = "x",
ylab = "beta distribution")
lines(x2, posterior2, type="l", lwd=2, col="blue")
legend("topright",
legend=c("prior2", "posterior2"),
col=c("red", "blue"),
lwd=2)
library(tidyverse)
library(tidymodels)
library(vroom)
library(ggplot2)
library(dbarts)
setwd("C://Users//Isaac//OneDrive//Documents//fall 2025 semester//STAT 348//BiekShare")
train <- vroom("train.csv")
test <- vroom("test.csv")
train_ud <- train |>
select(-casual, -registered) |>
mutate(count = log(count))
my_recipe <- recipe(count ~., data=train_ud) %>%
step_mutate(weather= factor(ifelse(weather == "4", "3", weather),
levels=c("1","2","3"),
labels=c("Clear", "Mist", "Light Snow"))) %>%
step_mutate(season = factor(season, levels=c("1","2","3","4"),
labels=c("Spring","Summer","Fall","Winter"))) %>%
#step_time(datetime, features="decimal_day")%>%
step_time(datetime, features="hour") %>%
step_dummy(all_nominal_predictors()) %>%
step_normalize(all_numeric_predictors())
prepped_recipe <- prep(my_recipe) # Sets up the preprocessing using myDataSet13
bake(prepped_recipe, new_data=train_ud)
bart_model <- parsnip::bart(trees=20) %>% # BART figures out depth and learn_rate
set_engine("dbarts") %>% # might need to install
set_mode("regression")
# auto_model <- auto_ml() %>%
# set_engine("h2o", max_runtime_secs=240, max_models=5) %>%
# set_mode("regression")
#
bart_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(bart_model) %>%
fit(data=train_ud)
#
bart_workflow %>%
predict(new_data = test)
my_recipe <- recipe(count ~., data=train_ud) %>%
step_mutate(weather= factor(ifelse(weather == "4", "3", weather),
levels=c("1","2","3"),
labels=c("Clear", "Mist", "Light Snow"))) %>%
step_mutate(season = factor(season, levels=c("1","2","3","4"),
labels=c("Spring","Summer","Fall","Winter"))) %>%
#step_time(datetime, features="decimal_day")%>%
step_time(datetime, features="hour") %>%
step_dummy(all_nominal_predictors()) %>%
step_normalize(all_numeric_predictors())
prepped_recipe <- prep(my_recipe) # Sets up the preprocessing using myDataSet13
bake(prepped_recipe, new_data=train_ud)
bart_model <- parsnip::bart(trees=500) %>% # BART figures out depth and learn_rate
set_engine("dbarts") %>% # might need to install
set_mode("regression")
# auto_model <- auto_ml() %>%
# set_engine("h2o", max_runtime_secs=240, max_models=5) %>%
# set_mode("regression")
#
bart_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(bart_model) %>%
fit(data=train_ud)
#
bart_grid <- grid_regular(trees(), levels = 5)
#
folds <- vfold_cv(train_ud, v = 5, repeats=1)
#
CV_results <- bart_workflow %>%
bart_grid(resamples=folds,
grid=bart_grid,
metrics=metric_set(rmse, mae))
# #
collect_metrics(CV_results) %>% # Gathers metrics into DF
filter(.metric=="rmse")
#
bart_grid <- grid_regular(trees(), levels = 5)
#
folds <- vfold_cv(train_ud, v = 5, repeats=1)
#
CV_results <- bart_workflow %>%
bart_grid(resamples=folds,
grid=bart_grid,
metrics=metric_set(rmse, mae))
my_recipe <- recipe(count ~., data=train_ud) %>%
step_mutate(weather= factor(ifelse(weather == "4", "3", weather),
levels=c("1","2","3"),
labels=c("Clear", "Mist", "Light Snow"))) %>%
step_mutate(season = factor(season, levels=c("1","2","3","4"),
labels=c("Spring","Summer","Fall","Winter"))) %>%
#step_time(datetime, features="decimal_day")%>%
step_time(datetime, features="hour") %>%
step_dummy(all_nominal_predictors()) %>%
step_normalize(all_numeric_predictors())
prepped_recipe <- prep(my_recipe) # Sets up the preprocessing using myDataSet13
bake(prepped_recipe, new_data=train_ud)
bart_model <- parsnip::bart(trees=500) %>% # BART figures out depth and learn_rate
set_engine("dbarts") %>% # might need to install
set_mode("regression")
# auto_model <- auto_ml() %>%
# set_engine("h2o", max_runtime_secs=240, max_models=5) %>%
# set_mode("regression")
#
bart_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(bart_model) %>%
fit(data=train_ud)
#
bart_grid <- grid_regular(trees(), levels = 5)
#
folds <- vfold_cv(train_ud, v = 5, repeats=1)
#
CV_results <- bart_workflow %>%
tune_grid(resamples=folds,
grid=bart_grid,
metrics=metric_set(rmse, mae))
# #
collect_metrics(CV_results) %>% # Gathers metrics into DF
filter(.metric=="rmse")
# final_wf <-
#   bart_workflow %>%
#   finalize_workflow(bestTune) %>%
#   fit(data=train_ud)
#
bart_workflow %>%
predict(new_data = test)
## Run all the steps on test data15
bart_predictions <- predict(auto_workflow, new_data = test)
## Run all the steps on test data15
bart_predictions <- predict(bart_workflow, new_data = test)
bart_predictions
kaggle_submission <- auto_predictions %>%
bind_cols(., test) %>%
select(datetime, .pred) %>%
rename(count=.pred) %>%
mutate(count=pmax(0, count)) %>%
mutate(count = exp(count)) %>%
mutate(datetime=as.character(format(datetime)))
kaggle_submission <- bart_predictions %>%
bind_cols(., test) %>%
select(datetime, .pred) %>%
rename(count=.pred) %>%
mutate(count=pmax(0, count)) %>%
mutate(count = exp(count)) %>%
mutate(datetime=as.character(format(datetime)))
vroom_write(x=kaggle_submission, file="./LinearPreds.csv", delim=",")
my_recipe <- recipe(count ~., data=train_ud) %>%
step_mutate(weather= factor(ifelse(weather == "4", "3", weather),
levels=c("1","2","3"),
labels=c("Clear", "Mist", "Light Snow"))) %>%
step_mutate(season = factor(season, levels=c("1","2","3","4"),
labels=c("Spring","Summer","Fall","Winter"))) %>%
#step_time(datetime, features="decimal_day")%>%
step_time(datetime, features="hour") %>%
step_dummy(all_nominal_predictors()) %>%
step_normalize(all_numeric_predictors())
prepped_recipe <- prep(my_recipe) # Sets up the preprocessing using myDataSet13
bake(prepped_recipe, new_data=train_ud)
bart_model <- parsnip::bart(trees=1000) %>% # BART figures out depth and learn_rate
set_engine("dbarts") %>% # might need to install
set_mode("regression")
# auto_model <- auto_ml() %>%
# set_engine("h2o", max_runtime_secs=240, max_models=5) %>%
# set_mode("regression")
#
bart_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(bart_model) %>%
fit(data=train_ud)
#
bart_grid <- grid_regular(trees(), levels = 5)
#
folds <- vfold_cv(train_ud, v = 5, repeats=1)
#
CV_results <- bart_workflow %>%
tune_grid(resamples=folds,
grid=bart_grid,
metrics=metric_set(rmse, mae))
# #
collect_metrics(CV_results) %>% # Gathers metrics into DF
filter(.metric=="rmse")
# final_wf <-
#   bart_workflow %>%
#   finalize_workflow(bestTune) %>%
#   fit(data=train_ud)
#
bart_workflow %>%
predict(new_data = test)
## Run all the steps on test data15
bart_predictions <- predict(bart_workflow, new_data = test)
bart_predictions
kaggle_submission <- bart_predictions %>%
bind_cols(., test) %>%
select(datetime, .pred) %>%
rename(count=.pred) %>%
mutate(count=pmax(0, count)) %>%
mutate(count = exp(count)) %>%
mutate(datetime=as.character(format(datetime)))
vroom_write(x=kaggle_submission, file="./LinearPreds.csv", delim=",")
my_recipe <- recipe(count ~., data=train_ud) %>%
step_mutate(weather= factor(ifelse(weather == "4", "3", weather),
levels=c("1","2","3"),
labels=c("Clear", "Mist", "Light Snow"))) %>%
step_mutate(season = factor(season, levels=c("1","2","3","4"),
labels=c("Spring","Summer","Fall","Winter"))) %>%
#step_time(datetime, features="decimal_day")%>%
step_time(datetime, features="hour") %>%
step_dummy(all_nominal_predictors()) %>%
step_normalize(all_numeric_predictors())
prepped_recipe <- prep(my_recipe) # Sets up the preprocessing using myDataSet13
bake(prepped_recipe, new_data=train_ud)
bart_model <- parsnip::bart(trees=2000) %>% # BART figures out depth and learn_rate
set_engine("dbarts") %>% # might need to install
set_mode("regression")
# auto_model <- auto_ml() %>%
# set_engine("h2o", max_runtime_secs=240, max_models=5) %>%
# set_mode("regression")
#
bart_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(bart_model) %>%
fit(data=train_ud)
#
bart_grid <- grid_regular(trees(), levels = 5)
#
folds <- vfold_cv(train_ud, v = 5, repeats=1)
#
CV_results <- bart_workflow %>%
tune_grid(resamples=folds,
grid=bart_grid,
metrics=metric_set(rmse, mae))
# #
collect_metrics(CV_results) %>% # Gathers metrics into DF
filter(.metric=="rmse")
# final_wf <-
#   bart_workflow %>%
#   finalize_workflow(bestTune) %>%
#   fit(data=train_ud)
#
bart_workflow %>%
predict(new_data = test)
## Run all the steps on test data15
bart_predictions <- predict(bart_workflow, new_data = test)
bart_predictions
kaggle_submission <- bart_predictions %>%
bind_cols(., test) %>%
select(datetime, .pred) %>%
rename(count=.pred) %>%
mutate(count=pmax(0, count)) %>%
mutate(count = exp(count)) %>%
mutate(datetime=as.character(format(datetime)))
vroom_write(x=kaggle_submission, file="./LinearPreds.csv", delim=",")
my_recipe <- recipe(count ~., data=train_ud) %>%
step_mutate(weather= factor(ifelse(weather == "4", "3", weather),
levels=c("1","2","3"),
labels=c("Clear", "Mist", "Light Snow"))) %>%
step_mutate(season = factor(season, levels=c("1","2","3","4"),
labels=c("Spring","Summer","Fall","Winter"))) %>%
#step_time(datetime, features="decimal_day")%>%
step_time(datetime, features="hour") %>%
step_dummy(all_nominal_predictors()) %>%
step_normalize(all_numeric_predictors())
prepped_recipe <- prep(my_recipe) # Sets up the preprocessing using myDataSet13
bake(prepped_recipe, new_data=train_ud)
bart_model <- parsnip::bart(trees=500) %>% # BART figures out depth and learn_rate
set_engine("dbarts") %>% # might need to install
set_mode("regression")
# auto_model <- auto_ml() %>%
# set_engine("h2o", max_runtime_secs=240, max_models=5) %>%
# set_mode("regression")
#
bart_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(bart_model) %>%
fit(data=train_ud)
#
bart_grid <- grid_regular(trees(), levels = 5)
#
folds <- vfold_cv(train_ud, v = 5, repeats=1)
#
CV_results <- bart_workflow %>%
tune_grid(resamples=folds,
grid=bart_grid,
metrics=metric_set(rmse, mae))
